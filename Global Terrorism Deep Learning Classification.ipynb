{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats.mstats import winsorize\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A deep learning neural network is used to classify terrorist attacks between 1970-2017 with \n",
    "unknown terrorist group affiliations. The model is trained on data provided by the Global Terrorism Database.\n",
    "The feature space includes categorical variables such as type of weapon used, victim type, suicide attacks, as well \n",
    "as numerical variables such as hostages taken, number of attackers, and number of fatalities.\n",
    "\n",
    "The model's accuracy on the validation test is approximately 60%.\n",
    "\n",
    "-Adam Wu\n",
    "\n",
    "Data:\n",
    "National Consortium for the Study of Terrorism and Responses to Terrorism (START). (2018). \n",
    "Global Terrorism Database [Data file]. Retrieved from https://www.start.umd.edu/gtd\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Development\\Python\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (4,6,31,33,61,62,63,76,79,90,92,94,96,114,115,121) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Reads the data and sets the index to 'eventid'. Missing values are encoded as -9,-99 according to database codebook.\n",
    "df = pd.read_csv('Data/globalterrorismdb_0718dist.csv', header=0, na_values = ['-9','-99']).set_index('eventid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are lots of missing data in the dataset and some variables only started recording in 1997.\n",
    "# Dropping all NaNs would result in significant loss of data, so impute missing values and reduce dimension of feature space.\n",
    "\n",
    "# However, for variables with significant amount of NaNs, imputing/aggregation may impose unrealistic assumptions about\n",
    "# the distributions of the variables and introduce bias. So variables with over 75% values NaN are excluded.\n",
    "pct_na = df.isna().sum()/len(df)\n",
    "ext_na = pct_na[~(pct_na > 0.75)]\n",
    "df = df.loc[:,ext_na.index.values]\n",
    "\n",
    "# For categorical variables, impute NaN with most common value (mode)\n",
    "cat = df.select_dtypes('int64')\n",
    "cat = cat.fillna(cat.mode())\n",
    "\n",
    "# For numerical variables, impute NaN with the mean. Since the mean is sensitive to large values,\n",
    "# winsorize (1%) to limit effect of extreme outliers\n",
    "num = df.select_dtypes('float64')\n",
    "num_no_nan = num.dropna()\n",
    "num_winsor = winsorize(num_no_nan, limits = [0.01, 0.01])\n",
    "num_mean = pd.DataFrame(num_winsor, index = num_no_nan.index, columns = num_no_nan.columns).mean()\n",
    "num = num.fillna(num_mean)\n",
    "num = pd.DataFrame(winsorize(num, limits = [0.01, 0.01]), index = num.index, columns = num.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model will be trained on a mixed feature space with both categorical and numerical variables.\n",
    "# Normalizing the feature variances may be useful and make the model more robust.\n",
    "\n",
    "# Since categorical variables have varied scaling (1-k), they are split into k-vectors with binary components.\n",
    "# In other words, N categorical variables with ranges of (k_1,...,k_N) are projected \n",
    "# onto an N*k-dimensional space with unit norm.\n",
    "cat_list = []\n",
    "for col in cat:\n",
    "    cat_list.append(pd.get_dummies(cat[col], prefix=str(col)))\n",
    "\n",
    "cat_df = reduce(lambda x,y: pd.merge(x,y,on='eventid'), cat_list)\n",
    "\n",
    "# Numerical variables are normalized to [0,1] so that they have similar scaling with the categorical variables\n",
    "num_scaled = (num - num.min(axis=0))/(num.max(axis=0) - num.min(axis=0))\n",
    "num_df = pd.DataFrame(num_scaled, index = num.index, columns = num.columns)\n",
    "\n",
    "df_clean = cat_df.merge(num_df, how='inner', on='eventid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indices of attacks with unknown terrorist affiliations. These are the attacks that will be classified\n",
    "# and predicted by the model.\n",
    "unknown = df[df['gname']=='Unknown'].index.values\n",
    "\n",
    "# Processed dataset of unknown attacks to classify\n",
    "X_to_classify = df_clean.loc[unknown,:]\n",
    "\n",
    "# Processed dataset of known attacks to train/test the model\n",
    "X_model = df_clean.drop(labels=unknown, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts terrorist group names into dummy variables\n",
    "terrorist_groups = df.loc[:,'gname']\n",
    "terrorist_groups_dummy = pd.get_dummies(terrorist_groups)\n",
    "\n",
    "# Unknown terrorist groups (in dummy form) to classify\n",
    "Y_to_classify = terrorist_groups_dummy.loc[unknown,:]\n",
    "\n",
    "# Known terrorist groups (in dummy form) to train/test the model\n",
    "Y_model = terrorist_groups_dummy.drop(labels=unknown, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79127 samples, validate on 19782 samples\n",
      "Epoch 1/20\n",
      "79127/79127 [==============================] - 198s 3ms/step - loss: 2.1518 - acc: 0.6257 - val_loss: 2.2647 - val_acc: 0.6574\n",
      "Epoch 2/20\n",
      "79127/79127 [==============================] - 204s 3ms/step - loss: 1.1742 - acc: 0.7391 - val_loss: 2.3010 - val_acc: 0.6386\n",
      "Epoch 3/20\n",
      "79127/79127 [==============================] - 212s 3ms/step - loss: 0.8862 - acc: 0.7794 - val_loss: 2.2492 - val_acc: 0.6538\n",
      "Epoch 4/20\n",
      "79127/79127 [==============================] - 221s 3ms/step - loss: 0.7075 - acc: 0.8083 - val_loss: 2.3626 - val_acc: 0.6188\n",
      "Epoch 5/20\n",
      "79127/79127 [==============================] - 222s 3ms/step - loss: 0.5708 - acc: 0.8370 - val_loss: 2.5199 - val_acc: 0.6164\n",
      "Epoch 6/20\n",
      "79127/79127 [==============================] - 213s 3ms/step - loss: 0.4655 - acc: 0.8670 - val_loss: 2.6457 - val_acc: 0.5980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e07d074b38>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model specifications\n",
    "\n",
    "# Dimension of feature space\n",
    "n_features = X_model.shape[1]\n",
    "n_groups = Y_model.shape[1]\n",
    "\n",
    "# Sets up a sequential neural network\n",
    "model = Sequential()\n",
    "\n",
    "# Input Layer\n",
    "model.add(Dense(500, activation='relu', input_shape=(n_features,)))\n",
    "\n",
    "# Hidden Layers\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "\n",
    "# Output Layer. Activation function is softmax so it returns probabilities for classification.\n",
    "model.add(Dense(n_groups, activation='softmax'))\n",
    "\n",
    "# Compilation\n",
    "model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Stop the training process early if performance does not improve \n",
    "early_stop = EarlyStopping(patience=3)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_model, Y_model,\n",
    "          epochs=20,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[early_stop,]\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predictions\n",
    "predictions = model.predict(X_to_classify)\n",
    "\n",
    "predict_df = pd.DataFrame(predictions, index=X_to_classify.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Terrorist Group Affiliation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201712290025</th>\n",
       "      <td>Muslim extremists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712290026</th>\n",
       "      <td>Fulani extremists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712300002</th>\n",
       "      <td>Sunni Muslim extremists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712300003</th>\n",
       "      <td>Sunni Muslim extremists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712300004</th>\n",
       "      <td>Muslim extremists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712300005</th>\n",
       "      <td>Sunni Muslim extremists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712300006</th>\n",
       "      <td>Guerrillas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712300007</th>\n",
       "      <td>Muslim extremists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712300010</th>\n",
       "      <td>Muslim Guerrillas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712300018</th>\n",
       "      <td>Donetsk People's Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712300019</th>\n",
       "      <td>Hindu extremists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712300021</th>\n",
       "      <td>Kashmiri extremists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712300022</th>\n",
       "      <td>Protestant extremists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712310001</th>\n",
       "      <td>Muslim extremists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712310002</th>\n",
       "      <td>Sunni Muslim extremists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712310011</th>\n",
       "      <td>Muslim Guerrillas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712310017</th>\n",
       "      <td>Anti-Semitic extremists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712310020</th>\n",
       "      <td>Taliban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712310031</th>\n",
       "      <td>Kashmiri extremists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712310032</th>\n",
       "      <td>Muslim Guerrillas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted Terrorist Group Affiliation\n",
       "eventid                                           \n",
       "201712290025                     Muslim extremists\n",
       "201712290026                     Fulani extremists\n",
       "201712300002               Sunni Muslim extremists\n",
       "201712300003               Sunni Muslim extremists\n",
       "201712300004                     Muslim extremists\n",
       "201712300005               Sunni Muslim extremists\n",
       "201712300006                            Guerrillas\n",
       "201712300007                     Muslim extremists\n",
       "201712300010                     Muslim Guerrillas\n",
       "201712300018             Donetsk People's Republic\n",
       "201712300019                      Hindu extremists\n",
       "201712300021                   Kashmiri extremists\n",
       "201712300022                 Protestant extremists\n",
       "201712310001                     Muslim extremists\n",
       "201712310002               Sunni Muslim extremists\n",
       "201712310011                     Muslim Guerrillas\n",
       "201712310017               Anti-Semitic extremists\n",
       "201712310020                               Taliban\n",
       "201712310031                   Kashmiri extremists\n",
       "201712310032                     Muslim Guerrillas"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Makes predictions for terrorist group affiliation based on maximum likelihood\n",
    "predicted_group = predict_df.idxmax(axis=1)\n",
    "predicted_group.head()\n",
    "\n",
    "reconstruct_group = []\n",
    "for row in predicted_group:\n",
    "    reconstruct_group.append(terrorist_groups_dummy.columns[row])\n",
    "    \n",
    "final_predictions = pd.DataFrame(reconstruct_group, index=predicted_group.index)\n",
    "final_predictions.columns = ['Predicted Terrorist Group Affiliation']\n",
    "\n",
    "final_predictions.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
